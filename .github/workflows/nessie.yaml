name: Nessie
on:
  workflow_dispatch:

jobs:
  nessie:
    name: Nessie tests
    runs-on: ubuntu-20.04
    steps:
      - name: Checkout
        uses: actions/checkout@v2

      - name: Setup UI (node 10)
        uses: actions/setup-node@v1
        with:
          node-version: '10.x'

      - name: Setup Go
        uses: actions/setup-go@v1
        with:
          go-version: 1.16.2
        id: go

      - name: Generate code
        run: make gen

      - name: Build image
        run: docker build -t treeverse.io/lakefs --build-arg VERSION=${{ steps.version.outputs.tag }} .

      - name: Setup Scala
        uses: olafurpg/setup-scala@v10

      - name: Compile Spark app
        working-directory: nessie/spark-app
        run: sbt package

      #- name: Test lakeFS local
        #env:
          #TAG: latest
          #REPO: treeverse.io
          #LAKEFS_STATS_ENABLED: "false"
          #LAKEFS_BLOCKSTORE_TYPE: local
          #LAKEFS_GATEWAYS_S3_DOMAIN_NAME: s3.local.lakefs.io:8000
          #NESSIE_TEST_DATA_ACCESS: false,false
          #NESSIE_STORAGE_NAMESPACE: local://nessie-system-testing
        #run: docker-compose -f nessie/ops/docker-compose.yaml --profile test up --exit-code-from=nessie

      - name: Test lakeFS local with Spark
        env:
          TAG: latest
          REPO: treeverse.io
          LAKEFS_STATS_ENABLED: "false"
          LAKEFS_BLOCKSTORE_TYPE: local
          LAKEFS_GATEWAYS_S3_DOMAIN_NAME: s3.local.lakefs.io:8000
          NESSIE_TEST_DATA_ACCESS: false,false
          NESSIE_STORAGE_NAMESPACE: local://nessie-system-testing
          TESTER_ACCESS_KEY_ID: AKIAIOSFODNN7EXAMPLE 
          TESTER_SECRET_ACCESS_KEY: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
        run: |
            docker-compose -f nessie/ops/docker-compose.yaml up -d
            docker-compose -f nessie/ops/docker-compose.yaml exec -T lakefs /app/wait-for localhost:8000
            echo "setup lakefs"
            docker-compose -f nessie/ops/docker-compose.yaml exec -T lakefs lakefs setup --user-name tester --access-key-id ${TESTER_ACCESS_KEY_ID} --secret-access-key ${TESTER_SECRET_ACCESS_KEY}
            echo "create example repository"
            docker-compose -f nessie/ops/docker-compose.yaml exec -T lakefs lakectl repo create lakefs://example ${NESSIE_STORAGE_NAMESPACE} -d master
            echo "update data-set"
            docker-compose -f nessie/ops/docker-compose.yaml exec -T -e LAKECTL_SERVER_ENDPOINT_URL=http://localhost:8000 -e LAKECTL_CREDENTIALS_ACCESS_KEY_ID=${TESTER_ACCESS_KEY_ID} -e LAKECTL_CREDENTIALS_SECRET_ACCESS_KEY=${TESTER_SECRET_ACCESS_KEY} lakefs lakectl fs upload -s /lakefs/spark-app/data-sets/sonnets.txt lakefs://example/master/sonnets.txt
            #docker-compose -f nessie/ops/docker-compose.yaml run -T --rm spark-submit spark-submit --master spark://spark:7077 -c "spark.hadoop.fs.s3a.access.key=${TESTER_ACCESS_KEY_ID}" -c "spark.hadoop.fs.s3a.secret.key=${TESTER_SECRET_ACCESS_KEY}" --class Sonnets /lakefs/nessie/spark-app/target/scala-2.12/sonnets_2.12-0.1.jar

      - name: lakeFS Logs on s3 failure
        if: ${{ failure() }}
        continue-on-error: true
        run: |
          docker-compose logs --tail=1000 lakefs
          docker-compose -f nessie/ops/docker-compose.yaml down --remove-orphans || true
